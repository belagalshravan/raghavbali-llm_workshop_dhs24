# LLM Workshop 2024

> [!IMPORTANT]
> :dart: [DataHack Summit 2024](https://www.analyticsvidhya.com/datahacksummit/workshops/unleashing-llms-training-finetuning-and-evaluating) | :calendar: August 10 2024 | :round_pushpin: Bengaluru, India

### Modules
#### Module 1: "Foundations of Generative AI and Language Models"
- [x] Overview of Generative AI and the basics of language modeling.
- [x] :star: Hands-On: 
    - [x] Getting Started: Text Representation
    - [x] Language Modeling Basics and Text Generation using a basic LM.

#### Module 2: "Building Blocks of LLMs"
- [ ] Transformer Architectures: Detailed look into the Transformer architecture that powers modern LLMs.
- [ ] GPT Series of Models: Overview of the evolution of GPT models.
- [ ] :star: Hands-On: Training a mini Transformer model and experimenting with GPT-2 for text generation.

#### Module 3: "Advanced LLM Techniques"
- [ ] Training Process and Scaling Laws: Understand how LLMs are trained and the laws governing their scaling.
- [ ] PEFT: Learn Parameter-Efficient Fine-Tuning methods.
- [ ] LoRA: Introduction to Low-Rank Adaptation.
- [ ] QLoRA: Exploring Quantized Low-Rank Adaptation.
- [ ] Instruction Tuning: Techniques for fine-tuning models using instructions.
- [ ] RLHF: Reinforcement Learning from Human Feedback and its applications.
- [ ] Evaluation Metrics and Benchmarks: Methods to evaluate and benchmark LLM performance.
- [ ] Beyond Prompting: Understanding Frameworks such as DSPY
- [ ] :star: Hands-On:
    - [ ] Fine-tuning a pre-trained model using different methods and evaluating it with standard benchmarks.
    - [ ] Handson with DSPY

#### Module 4: "Operationalizing LLMs"
- [ ] OpenSource vs Commercial LLMs: Comparison between open-source and commercial LLM solutions.
- [ ] Prompt Engineering: Crafting effective prompts to get desired outputs.
- [ ] RAGs: Techniques for retrieval-augmented generation.
- [ ] Vector Databases: Using vector databases for efficient data retrieval.
- [ ] Chunking and Ingesting Documents: Methods for processing and ingesting documents.
- [ ] Securing LLMs
- [ ] Prompt Hacking and Backdoors
- [ ] Defensive Measures
- [ ] :star: Hands-On:
    - [ ] Implementing basic prompt engineering techniques and
    - [ ] Building a simple RAG system.

#### Module 5: "The Future of LLMs and Next Steps"
- Multi-modal: Integration of different data modalities in LLMs.
- Mixture of Experts: Using a mixture of expert models for improved performance.
- SLM: Introduction to Small LMs.
- Ethics and Bias in LLMs: Understanding and mitigating biases in LLMs.
- Next Steps: Speculative topics on future advancements.
- GPT5?: What to expect from the next generation of GPT.
- Beyond: Future possibilities and directions for LLM research.
-  :star: Hands-On: (If time permits) Experimenting with multi-modal models and mixture of experts.

---


> [!Note]
> Prerequisites
- Basics/hands-on experience of working with python
- Basic understanding of linear algebra and machine larning
- Basic understanding of Deep Neural Networks
- Basics/hands-on experience with pytorch
- Access to google-colab or similar python environment
- Access to chatGPT or Google-Bard (free access) 